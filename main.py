from agent import InvestmentAgent
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import os

# API í‚¤ ì„¤ì •
OPENAI_API_KEY = "your-openai-key-here"
PERPLEXITY_API_KEY = "your-perplexity-key-here"


def check_pdf_file(pdf_path: str):
    """PDF íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸"""
    print(f"\nğŸ” PDF íŒŒì¼ í™•ì¸: {pdf_path}")

    # ì ˆëŒ€ ê²½ë¡œ í™•ì¸
    abs_path = os.path.abspath(pdf_path)
    print(f"   ì ˆëŒ€ ê²½ë¡œ: {abs_path}")

    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
    current_dir = os.getcwd()
    print(f"   í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {current_dir}")

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
    if os.path.exists(pdf_path):
        print(f"   âœ“ íŒŒì¼ ì¡´ì¬í•¨")

        # íŒŒì¼ í¬ê¸°
        file_size = os.path.getsize(pdf_path)
        print(f"   âœ“ íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size / 1024:.2f} KB)")

        # ì½ê¸° ê¶Œí•œ í™•ì¸
        if os.access(pdf_path, os.R_OK):
            print(f"   âœ“ ì½ê¸° ê¶Œí•œ ìˆìŒ")
        else:
            print(f"   âŒ ì½ê¸° ê¶Œí•œ ì—†ìŒ")
            return False

        # íŒŒì¼ í™•ì¥ì í™•ì¸
        if not pdf_path.lower().endswith('.pdf'):
            print(f"   âš ï¸ PDF í™•ì¥ìê°€ ì•„ë‹™ë‹ˆë‹¤")

        return True
    else:
        print(f"   âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ PDF íŒŒì¼ ì°¾ê¸°
        print(f"\n   í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ PDF íŒŒì¼ ëª©ë¡:")
        pdf_files = [f for f in os.listdir(current_dir) if f.lower().endswith('.pdf')]
        if pdf_files:
            for pdf in pdf_files:
                print(f"   - {pdf}")
        else:
            print(f"   (PDF íŒŒì¼ ì—†ìŒ)")

        return False


def inspect_pdf_processing(pdf_path: str, openai_api_key: str):
    """PDFê°€ ì–´ë–»ê²Œ ë¡œë“œë˜ê³  ë²¡í„°í™”ë˜ì—ˆëŠ”ì§€ ìƒì„¸ í™•ì¸"""

    print("=" * 60)
    print("ğŸ“‹ PDF ì²˜ë¦¬ ê³¼ì • ë¶„ì„")
    print("=" * 60)

    # íŒŒì¼ í™•ì¸ ë¨¼ì € ì‹¤í–‰
    if not check_pdf_file(pdf_path):
        print("\nâŒ PDF íŒŒì¼ ì ‘ê·¼ ë¶ˆê°€. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

    # 1. PDF ë¡œë“œ
    print("\n[1ë‹¨ê³„] PDF ë¡œë”©...")
    try:
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()

        if not documents:
            print("âŒ PDFëŠ” ë¡œë“œë˜ì—ˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        print(f"âœ“ ì´ í˜ì´ì§€ ìˆ˜: {len(documents)}í˜ì´ì§€")
        print(f"\nì²« ë²ˆì§¸ í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
        print("-" * 60)
        first_content = documents[0].page_content[:500]
        print(first_content if first_content else "(ë¹ˆ í˜ì´ì§€)")
        print("-" * 60)
    except Exception as e:
        print(f"âŒ PDF ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    print("\n[2ë‹¨ê³„] í…ìŠ¤íŠ¸ ë¶„í• ...")
    try:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)

        if not splits:
            print("âŒ í…ìŠ¤íŠ¸ ë¶„í•  ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        print(f"âœ“ ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(splits)}ê°œ")
        print(f"\nì²­í¬ ì˜ˆì‹œ (ì²˜ìŒ 3ê°œ):")
        for i, split in enumerate(splits[:3]):
            print(f"\n--- ì²­í¬ #{i + 1} ---")
            print(f"í˜ì´ì§€: {split.metadata.get('page', 'N/A')}")
            print(f"ê¸¸ì´: {len(split.page_content)} ê¸€ì")
            print(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:")
            content_preview = split.page_content[:300]
            print(content_preview if content_preview else "(ë¹ˆ ì²­í¬)")
            if content_preview:
                print("...")
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None

    # 3. ë²¡í„°í™” ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n[3ë‹¨ê³„] ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    try:
        os.environ["OPENAI_API_KEY"] = openai_api_key

        embeddings = OpenAIEmbeddings()
        print("   ì„ë² ë”© ìƒì„± ì¤‘...")
        vector_store_test = FAISS.from_documents(splits, embeddings)
        print("   âœ“ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "investment philosophy",
            "competitive advantage",
            "ê²½ì œì  í•´ì",
            "valuation"
        ]

        print(f"\nê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        for query in test_queries:
            print(f"\nğŸ” ê²€ìƒ‰ì–´: '{query}'")
            results = vector_store_test.similarity_search(query, k=2)
            if not results:
                print(f"   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            for j, doc in enumerate(results):
                print(f"  [{j + 1}] ìœ ì‚¬ë„ ë†’ì€ ì²­í¬ (í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}):")
                print(f"      {doc.page_content[:200]}...")
    except Exception as e:
        print(f"âŒ ë²¡í„°í™” ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None

    # 4. í†µê³„ ì •ë³´
    print("\n" + "=" * 60)
    print("ğŸ“Š ìš”ì•½ í†µê³„")
    print("=" * 60)
    total_chars = sum(len(split.page_content) for split in splits)
    avg_chunk_size = total_chars / len(splits) if splits else 0

    print(f"ì „ì²´ ë¬¸ì ìˆ˜: {total_chars:,} ê¸€ì")
    print(f"í‰ê·  ì²­í¬ í¬ê¸°: {avg_chunk_size:.0f} ê¸€ì")
    if splits:
        print(f"ìµœì†Œ ì²­í¬ í¬ê¸°: {min(len(s.page_content) for s in splits)} ê¸€ì")
        print(f"ìµœëŒ€ ì²­í¬ í¬ê¸°: {max(len(s.page_content) for s in splits)} ê¸€ì")

    return {
        "documents": documents,
        "splits": splits,
        "vector_store": vector_store_test
    }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # PDF ê²½ë¡œ
    pdf_path = os.path.abspath('stockking.pdf')

    print("\n" + "=" * 60)
    print("ğŸš€ ë²„í• ìŠ¤íƒ€ì¼ ì£¼ì‹ ë¶„ì„ê¸°")
    print("=" * 60)

    if not os.path.exists(pdf_path):
        print(f"âš ï¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        print("í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ PDF íŒŒì¼:")
        current_dir = os.getcwd()
        pdf_files = [f for f in os.listdir(current_dir) if f.lower().endswith('.pdf')]
        for pdf in pdf_files:
            print(f"  - {pdf}")

        if pdf_files:
            pdf_path = os.path.join(current_dir, pdf_files[0])
            print(f"\nì²« ë²ˆì§¸ PDF ì‚¬ìš©: {pdf_path}")
        else:
            pdf_path = None
            print("\nPDF ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤ (ê¸°ë³¸ íˆ¬ì ì›ì¹™ ì‚¬ìš©)")
    # ë©”ë‰´ ì„ íƒ
    print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. PDF ì²˜ë¦¬ ê³¼ì • í™•ì¸")
    print("2. ì£¼ì‹ ë¶„ì„ ì‹¤í–‰")
    print("3. ë‘˜ ë‹¤ ì‹¤í–‰")

    choice = input("\nì„ íƒ (1/2/3): ").strip()

    # PDF ê²€ì‚¬ ì‹¤í–‰
    if choice in ["1", "3"]:
        print("\n" + "=" * 60)
        print("ğŸ“„ PDF ê²€ì‚¬ ì‹œì‘")
        print("=" * 60)
        inspection_result = inspect_pdf_processing(pdf_path, OPENAI_API_KEY)

        if inspection_result is None:
            print("\nâŒ PDF ê²€ì‚¬ ì‹¤íŒ¨.")

            # ëŒ€ì•ˆ ê²½ë¡œ ì œì•ˆ
            alt_path = input("\në‹¤ë¥¸ PDF ê²½ë¡œë¥¼ ì…ë ¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ê²½ë¡œ ì…ë ¥ ë˜ëŠ” Enterë¡œ ê±´ë„ˆë›°ê¸°): ").strip()
            if alt_path and os.path.exists(alt_path):
                pdf_path = alt_path
                inspection_result = inspect_pdf_processing(pdf_path, OPENAI_API_KEY)
            elif choice == "1":
                return
        else:
            print("\nâœ… PDF ê²€ì‚¬ ì™„ë£Œ!")

    # ì£¼ì‹ ë¶„ì„ ì‹¤í–‰
    if choice in ["2", "3"]:
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ì£¼ì‹ ë¶„ì„ ì‹œì‘")
        print("=" * 60)




        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (PDF ê²½ë¡œ í¬í•¨)
        print(f"\nğŸ”§ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        print(f"   ğŸ“„ PDF ê²½ë¡œ: {pdf_path if pdf_path else 'ì—†ìŒ (RAG ë¹„í™œì„±í™”)'}")

        agent = InvestmentAgent(
            openai_api_key=OPENAI_API_KEY,
            perplexity_api_key=PERPLEXITY_API_KEY,
            pdf_path=pdf_path  # PDF ê²½ë¡œ ì „ë‹¬
        )

        # RAG ì´ˆê¸°í™” í™•ì¸
        if agent.vector_store:
            print(f"   âœ“ RAG ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            print(f"   âš ï¸ RAG ë¯¸í™œì„±í™” (PDF ì—†ìŒ)")


        # ì‚¬ìš©ì ì…ë ¥
        user_query = input("\në¶„ì„í•  ì£¼ì‹ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: what is iren?): ").strip()
        if not user_query:
            user_query = "what is iren?"
            print(f"ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©: {user_query}")

        # ë¶„ì„ ì‹¤í–‰
        try:
            result = agent.analyze_stock(
                user_query=user_query,
                pdf_path=None  # ì´ë¯¸ ì´ˆê¸°í™” ì‹œ ì„¤ì •ë¨
            )

            # ê²°ê³¼ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ“Š ìµœì¢… ë¶„ì„ ê²°ê³¼")
            print("=" * 60)
            print(result["final_analysis"])

            # ì¶”ê°€ ì •ë³´
            if result.get("error"):
                print(f"\nâš ï¸ ê²½ê³ : {result['error']}")

            # ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            save = input("\nê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if save == 'y':
                filename = f"ë¶„ì„ê²°ê³¼_{user_query[:20].replace(' ', '_')}.txt"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write("=" * 60 + "\n")
                    f.write("ğŸ“Š íˆ¬ì ë¶„ì„ ê²°ê³¼\n")
                    f.write("=" * 60 + "\n\n")
                    f.write(f"ì§ˆë¬¸: {user_query}\n\n")
                    f.write(result["final_analysis"])
                    f.write("\n\n" + "=" * 60 + "\n")
                    f.write("ğŸ“š ì‹œì¥ ë°ì´í„°\n")
                    f.write("=" * 60 + "\n\n")
                    f.write(result["market_data"].get("raw_response", "ì •ë³´ ì—†ìŒ"))
                print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")

        except Exception as e:
            print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            print(traceback.format_exc())


if __name__ == "__main__":
    main()
