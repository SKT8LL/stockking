import os
import requests
from typing import TypedDict, List
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langgraph.graph import StateGraph, END


class InvestmentState(TypedDict):
    user_query: str
    market_data: dict
    buffett_insights: List[str]
    final_analysis: str
    error: str
    perplexity_max_tokens: int
    perplexity_temperature: float
    openai_max_tokens: int
    openai_temperature: float


class InvestmentAgent:
    def __init__(self, openai_api_key: str, perplexity_api_key: str):
        self.openai_api_key = openai_api_key
        self.perplexity_api_key = perplexity_api_key
        self.vector_store = None
        os.environ["OPENAI_API_KEY"] = openai_api_key

    def perplexity_research_node(self, state: InvestmentState) -> InvestmentState:
        """Perplexity APIë¡œ ì •ë³´ ìˆ˜ì§‘"""
        user_query = state["user_query"]
        max_tokens = state.get("perplexity_max_tokens", 1500)
        temperature = state.get("perplexity_temperature", 0.2)

        print(f"ğŸ” Perplexityë¡œ ì •ë³´ ìˆ˜ì§‘ ì¤‘: '{user_query}'")
        print(f"   ğŸ“Š ì„¤ì •: max_tokens={max_tokens}, temperature={temperature}")

        try:
            url = "https://api.perplexity.ai/chat/completions"
            payload = {
                "model": "sonar-pro",
                "messages": [
                    {
                        "role": "system",
                        "content": """You are a financial data researcher. When asked about a stock:
1. Identify the company and ticker symbol
2. Provide current stock price and today's change
3. Recent news (last 7 days)
4. Analyst ratings summary
5. Key financial metrics (P/E, market cap, revenue growth)
6. Major risks or concerns

Be concise and factual. Always include the ticker symbol in your response.
Only use information from reliable financial sources."""
                    },
                    {"role": "user", "content": user_query}
                ],
                "max_tokens": max_tokens,
                "temperature": temperature,
                "return_citations": True,
                "search_domain_filter": [
                    "bloomberg.com", "reuters.com", "wsj.com",
                    "finance.yahoo.com", "investing.com", "seekingalpha.com"
                ]
            }

            headers = {
                "Authorization": f"Bearer {self.perplexity_api_key}",
                "Content-Type": "application/json"
            }

            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()

            result = response.json()
            market_data = {
                "raw_response": result["choices"][0]["message"]["content"],
                "citations": result.get("citations", []),
                "user_query": user_query
            }

            print(f"âœ“ Perplexity ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            return {**state, "market_data": market_data}

        except Exception as e:
            print(f"âŒ Perplexity API ì˜¤ë¥˜: {str(e)}")
            return {
                **state,
                "market_data": {
                    "raw_response": f"ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}",
                    "user_query": user_query
                },
                "error": str(e)
            }

    def initialize_rag(self, pdf_path: str):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print(f"ğŸ“„ PDF ë¡œë”© ì¤‘: {pdf_path}")

        loader = PyPDFLoader(pdf_path)
        documents = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)

        embeddings = OpenAIEmbeddings()
        self.vector_store = FAISS.from_documents(splits, embeddings)

        print(f"âœ“ RAG ì´ˆê¸°í™” ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")

    def rag_buffett_wisdom_node(self, state: InvestmentState) -> InvestmentState:
        """ë²„í¬ì…” ì„œí•œì—ì„œ íˆ¬ì ì² í•™ ê²€ìƒ‰"""
        user_query = state["user_query"]
        print(f"ğŸ“š ë²„í•ì˜ íˆ¬ì ì² í•™ ê²€ìƒ‰ ì¤‘...")

        if self.vector_store is None:
            print("âš ï¸ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì›ì¹™ ì‚¬ìš©")
            return {
                **state,
                "buffett_insights": [
                    "ê²½ì œì  í•´ì(Economic Moat)ê°€ ìˆëŠ” ê¸°ì—…ì„ ì°¾ì•„ë¼",
                    "ì´í•´í•  ìˆ˜ ìˆëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì—ë§Œ íˆ¬ìí•˜ë¼",
                    "í›Œë¥­í•œ ê²½ì˜ì§„ì´ ìˆëŠ”ê°€ë¥¼ í™•ì¸í•˜ë¼",
                    "ì ì • ê°€ê²©ì— ë§¤ìˆ˜í•˜ë¼"
                ]
            }

        search_queries = [
            user_query,
            "competitive advantage moat",
            "business quality evaluation",
            "valuation principles"
        ]

        insights = []
        for query in search_queries[:3]:
            docs = self.vector_store.similarity_search(query, k=2)
            for doc in docs:
                insights.append(doc.page_content[:300])

        print(f"âœ“ {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
        return {**state, "buffett_insights": insights}

    def openai_analysis_node(self, state: InvestmentState) -> InvestmentState:
        """OpenAIë¡œ ì¢…í•© ë¶„ì„"""
        user_query = state["user_query"]
        market_data = state["market_data"]
        buffett_insights = state["buffett_insights"]
        max_tokens = state.get("openai_max_tokens", 2000)
        temperature = state.get("openai_temperature", 0.3)

        print(f"ğŸ¤– OpenAIë¡œ ì¢…í•© ë¶„ì„ ì¤‘...")
        print(f"   ğŸ“Š ì„¤ì •: max_tokens={max_tokens}, temperature={temperature}")

        prompt = f"""ë‹¹ì‹ ì€ ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì² í•™ì„ ê¹Šì´ ì´í•´í•˜ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

## Perplexityê°€ ìˆ˜ì§‘í•œ ìµœì‹  ì‹œì¥ ì •ë³´
{market_data.get('raw_response', 'ì •ë³´ ì—†ìŒ')}

## ë²„í¬ì…” í•´ì„œì›¨ì´ ì„œí•œì—ì„œ ì¶”ì¶œí•œ íˆ¬ì ì›ì¹™
{chr(10).join(f"- {insight[:200]}..." for insight in buffett_insights)}

## ë¶„ì„ ìš”ì²­
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•˜ì„¸ìš”:

1. **íšŒì‚¬ ë° í‹°ì»¤ í™•ì¸**
2. **ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ë„** (1-5ì )
3. **ê²½ì œì  í•´ì** (1-5ì )
4. **ê²½ì˜ì§„ í‰ê°€** (1-5ì )
5. **ë°¸ë¥˜ì—ì´ì…˜** (1-5ì )
6. **ì¢…í•© íˆ¬ì ì˜ê²¬**

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        try:
            llm = ChatOpenAI(
                model="gpt-4o",
                temperature=temperature,
                max_tokens=max_tokens
            )
            response = llm.invoke(prompt)
            analysis = response.content

            print(f"âœ“ ë¶„ì„ ì™„ë£Œ ({len(analysis)} ê¸€ì)")
            return {**state, "final_analysis": analysis}

        except Exception as e:
            print(f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}")
            return {
                **state,
                "final_analysis": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "error": str(e)
            }

    def create_workflow(self):
        """ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(InvestmentState)

        workflow.add_node("perplexity_research", self.perplexity_research_node)
        workflow.add_node("rag_wisdom", self.rag_buffett_wisdom_node)
        workflow.add_node("openai_analysis", self.openai_analysis_node)

        workflow.set_entry_point("perplexity_research")
        workflow.add_edge("perplexity_research", "rag_wisdom")
        workflow.add_edge("rag_wisdom", "openai_analysis")
        workflow.add_edge("openai_analysis", END)

        return workflow.compile()

    def analyze_stock(
        self,
        user_query: str,
        pdf_path: str = None,
        perplexity_max_tokens: int = 1500,
        perplexity_temperature: float = 0.2,
        openai_max_tokens: int = 2000,
        openai_temperature: float = 0.3
    ):
        """ì£¼ì‹ ë¶„ì„ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ¯ ë²„í• ìŠ¤íƒ€ì¼ ì£¼ì‹ ë¶„ì„ ì‹œì‘")
        print("=" * 60)

        print("pdf path :" + pdf_path)
        if pdf_path:
            self.initialize_rag(pdf_path)

        app = self.create_workflow()

        initial_state = {
            "user_query": user_query,
            "market_data": {},
            "buffett_insights": [],
            "final_analysis": "",
            "error": "",
            "perplexity_max_tokens": perplexity_max_tokens,
            "perplexity_temperature": perplexity_temperature,
            "openai_max_tokens": openai_max_tokens,
            "openai_temperature": openai_temperature
        }

        result = app.invoke(initial_state)

        print("\n" + "=" * 60)
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        print("=" * 60)
        print(result["final_analysis"])

        if result.get("error"):
            print(f"\nâš ï¸ ê²½ê³ : {result['error']}")

        return result
